#!/usr/bin/env python
from __future__ import annotations

import pysam
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing
import os
from datetime import datetime
from tqdm import tqdm
from tqdm.contrib.concurrent import process_map
import sys

#import multiprocessing as mp

from functools import partial
import re
import numpy as np
import pandas as pd
import argparse

pd.options.mode.chained_assignment = None


def ungap_pos(row, overhang_cutoff=5):
    if row['ori'] == 'f' and row['overhang'] <= overhang_cutoff:
        return row['pos'] + row['gap']
    elif row['ori'] == 'r' and row['overhang'] <= overhang_cutoff:
        return row['pos'] - row['gap']
    else:
        return row['pos']  
    

# def calculate_depth_for_row(row, bamfile, width):
#     return calculate_depth_default(bamfile, row["chr"], row["ungap_pos"], row["ori"], width)

# def init(pbar_total):
#     global pbar
#     pbar = tqdm(total=pbar_total)


def calculate_depth_default(bamfile, chrom, pos, ori, width=10):
    # Get SAMtools version
    version_string = pysam.samtools.version()
    match = re.search(r'samtools (\d+\.\d+)', version_string)
    samtools_version = match.group(1)

    major_ver = int(samtools_version.split()[0].split('.')[0])
    minor_ver = int(samtools_version.split()[0].split('.')[1])
    
    
    # Check SAMtools version
    if major_ver < 1 or minor_ver < 10:
        raise ValueError("SAMtools version 1.10 or higher is required.")

    # Define region based on orientation
    if ori == "f":
        region = f"{chrom}:{pos}-{pos + width}"
    else:
        region = f"{chrom}:{pos - width - 1}-{pos - 1}"
        
    #print(region)
            
    depths=pysam.depth("-Q","1","-g","4095","-a",bamfile,"-r",region)

    # Split the output into lines
    lines = depths.split('\n')

    # Extract the depth values from the third column of each line
    depths = [int(line.split('\t')[2]) for line in lines if line]

    # Get the maximum depth
    max_depth = max(depths)
    
    #pbar.update(1)
    
    return max_depth


def calculate_depth_for_chunk(chunk, bamfile=None, width=None):
    # result = chunk.apply(
    #     lambda row: calculate_depth_default(bamfile, row["chr"], row["ungap_pos"], row["ori"], width),
    #     #lambda row: calculate_depth_default(bamfile, row["chr"], row["ungap_pos"], row["ori"], pbar, width),
    #     axis=1
    # )
    # if pbar:
    #     pbar.update(1)

    # return result

    # return chunk.apply(
    #     lambda row: calculate_depth_default(bamfile, row["chr"], row["ungap_pos"], row["ori"], width),
    #     #lambda row: calculate_depth_default(bamfile, row["chr"], row["ungap_pos"], row["ori"], pbar, width),
    #     axis=1
    # )
    process_id = multiprocessing.current_process().pid

    # Use max and min, like minux max_cpu number
    # How I can get the total multiprocessing.process IDs? 

    with tqdm(total=len(chunk), desc=f"Processing Chunk PID:{process_id}") as pbar:  # Create a tqdm progress bar for each chunk
        def calculate_depth_for_row(row):
            nonlocal pbar
            result = calculate_depth_default(bamfile, row["chr"], row["ungap_pos"], row["ori"], width)
            pbar.update(1)  # Update the progress bar for each row
            return result

        return chunk.apply(calculate_depth_for_row, axis=1)
    

def calculate_depth_rtea(rtea, bamfile, width=10, cpus=None):

    rtea = pd.read_csv(rtea,sep="\t")
    
    rtea['ungap_pos'] = rtea.apply(lambda row: ungap_pos(row), axis=1).round().astype(int)
    
    # Get the start time
    start_time = datetime.now()
    
    # Use the number of threads specified or default to the number of available CPUs
    num_cpus = cpus if cpus is not None else mp.cpu_count() - 1
            
    print(f"number of cpus: {num_cpus}")

    # Function to apply calculate_depth_default to a chunk of the DataFrame
    # def calculate_depth_for_chunk(chunk, pbar):


    # Determine the number of elements per chunk
    # elements_per_chunk = len(rtea) // num_cpus
        
    # Split the DataFrame into chunks, handling the remainder

    # Create a partial function with fixed arguments
    partial_calculate_depth = partial(calculate_depth_for_chunk, bamfile=bamfile, width=width)


    chunks = np.array_split(rtea, num_cpus)
    
    
    #with tqdm(total=len(rtea)) as pbar:
    #with tqdm(total=len(chunks)) as pbar:
    
    with multiprocessing.Pool(processes=num_cpus) as pool:
    #with multiprocessing.Pool(processes=num_cpus, initializer=init, initargs=(len(chunks),)) as pool:
        

        #results = list(process_map(partial_calculate_depth, chunks, pool=pool, pbar=main_pbar, desc="Processing", total=len(chunks)))
        results = list(tqdm(pool.imap_unordered(partial_calculate_depth, chunks), total=len(chunks)))

    depths = pd.concat(results, axis=0)


        # Assign the depths to the original DataFrame
        
    # Get the end time
    end_time = datetime.now()

        
    # Calculate processed time
    processed_time = end_time - start_time

    # Print information
    print(f"Start Time: {start_time}")
    print(f"End Time: {end_time}")
    print(f"Processed Time: {processed_time}")
    
    rtea["depth"] = depths
    rtea["vaf"]=round(rtea['matchCnt']/rtea['depth'],5)
    

    return rtea

def main():
    # Create an argument parser
    parser = argparse.ArgumentParser(description="Script for calculating depth using rtea and bam files.")
    
    # Add arguments for rtea, bamfile, and output
    parser.add_argument('-r', '--rtea', help='Path to the rtea file', required=True)
    parser.add_argument('-b', '--bam', help='Path to the bam file', required=True)
    parser.add_argument('-o', '--output', help='Output file name', required=True)
    parser.add_argument('-c', '--core', help='Number of cores', required=True)

    # Parse the command-line arguments
    args = parser.parse_args()

    # Check if input files exist
    if not os.path.isfile(args.rtea):
        print(f"Error: The file '{args.rtea}' does not exist.")
        sys.exit(1)

    if not os.path.isfile(args.bam):
        print(f"Error: The file '{args.bam}' does not exist.")
        sys.exit(1)

    # Perform the calculation
    
    result = calculate_depth_rtea(args.rtea, args.bam, 10, int(args.core))

    # Save the result to the output file
    result.to_csv(args.output, sep='\t', header=True)
    print(f"Calculation completed. Results saved to '{args.output}'.")
    
if __name__ == "__main__":
    main()    
